"""
YOLOv12 Human Detector - Improved Version
Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ Ï„Î¿ Ï€Î¹Î¿ Ï€ÏÏŒÏƒÏ†Î±Ï„Î¿ YOLOv12 model Î³Î¹Î± person detection
"""

from ultralytics import YOLO
import numpy as np
from pathlib import Path
import cv2


def get_available_device(device_preference=None):
    """
    Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î¿Ï… device (CPU/GPU)
    
    Args:
        device_preference: 'cuda', 'cpu', Î® None Î³Î¹Î± auto-detection
        
    Returns:
        device string ('cuda', 'cpu', 'mps', etc.)
    """
    try:
        import torch
        
        if device_preference == 'cpu':
            return 'cpu'
        elif device_preference == 'cuda':
            if torch.cuda.is_available():
                return 'cuda'
            else:
                print("âš ï¸ CUDA requested but not available, falling back to CPU")
                return 'cpu'
        else:
            # Auto-detection
            if torch.cuda.is_available():
                return 'cuda'
            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                return 'mps'  # Apple Silicon
            else:
                return 'cpu'
    except ImportError:
        print("âš ï¸ PyTorch not installed, using CPU")
        return 'cpu'


class HumanDetector:
    """Detector Î³Î¹Î± Î±Î½Î¸ÏÏŽÏ€Î¿Ï…Ï‚ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏŽÎ½Ï„Î±Ï‚ YOLOv12"""

    def __init__(self, model_path="models/yolo12n.pt", confidence=0.3, iou_threshold=0.45, device=None):
        """
        Args:
            model_path: Path Î³Î¹Î± Ï„Î¿ YOLOv12 model
            confidence: Minimum confidence threshold (Î¼ÎµÎ¹Ï‰Î¼Î­Î½Î¿ Î³Î¹Î± ÎºÎ±Î»ÏÏ„ÎµÏÎ¿ detection)
            iou_threshold: IoU threshold Î³Î¹Î± NMS
            device: 'cuda', 'cpu', Î® None Î³Î¹Î± auto-detection
        """
        self.confidence = confidence
        self.iou_threshold = iou_threshold
        self.model_path = Path(model_path)
        
        # Device selection
        self.device = get_available_device(device)
        self.device_name = self._get_device_name()

        # Î¦ÏŒÏÏ„Ï‰ÏƒÎ· YOLOv12 model
        print(f"ðŸ“¦ Î¦ÏŒÏÏ„Ï‰ÏƒÎ· YOLOv12 model Î±Ï€ÏŒ {model_path}...")
        print(f"ðŸ–¥ï¸  Device: {self.device_name}")
        self.model = YOLO(model_path)
        
        # Set device Î³Î¹Î± Ï„Î¿ model
        if self.device != 'cpu':
            try:
                self.model.to(self.device)
            except Exception as e:
                print(f"âš ï¸ Could not set device to {self.device}: {e}")
                print("   Falling back to CPU")
                self.device = 'cpu'
                self.device_name = "CPU"
        
        print("âœ… Model Ï†Î¿ÏÏ„ÏŽÎ¸Î·ÎºÎµ ÎµÏ€Î¹Ï„Ï…Ï‡ÏŽÏ‚!")

        # COCO dataset: class 0 = person
        self.person_class_id = 0
    
    def _get_device_name(self):
        """Î•Ï€Î¹ÏƒÏ„ÏÎ¿Ï†Î® user-friendly device name"""
        try:
            import torch
            if self.device == 'cuda':
                gpu_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else "CUDA"
                return f"GPU ({gpu_name})"
            elif self.device == 'mps':
                return "Apple Silicon (MPS)"
            else:
                return "CPU"
        except (ImportError, AttributeError, RuntimeError):
            return "CPU"

    def detect(self, frame):
        """
        Î‘Î½Î¯Ï‡Î½ÎµÏ…ÏƒÎ· Î±Î½Î¸ÏÏŽÏ€Ï‰Î½ ÏƒÎµ Î­Î½Î± frame

        Args:
            frame: Input frame (numpy array)

        Returns:
            detections: numpy array of [x1, y1, x2, y2, confidence]
        """
        # Î¤ÏÎ­Ï‡Î¿Ï…Î¼Îµ Ï„Î¿ YOLOv12 model Î¼Îµ Î²ÎµÎ»Ï„Î¹Ï‰Î¼Î­Î½ÎµÏ‚ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï…Ï‚
        results = self.model(
            frame,
            conf=self.confidence,
            iou=self.iou_threshold,
            verbose=False,
            classes=[0],  # ÎœÏŒÎ½Î¿ person class
            device=self.device  # Explicit device specification
        )

        detections = []

        # Î•Î¾Î±Î³Ï‰Î³Î® detections Î¼ÏŒÎ½Î¿ Î³Î¹Î± Î±Î½Î¸ÏÏŽÏ€Î¿Ï…Ï‚ (class 0)
        for result in results:
            boxes = result.boxes

            for box in boxes:
                # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±Î½ ÎµÎ¯Î½Î±Î¹ person
                if int(box.cls) == self.person_class_id:
                    # Î£Ï…Î½Ï„ÎµÏ„Î±Î³Î¼Î­Î½ÎµÏ‚ bounding box
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    conf = float(box.conf[0])

                    # Î¦Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î± Ï€Î¿Î»Ï Î¼Î¹ÎºÏÏŽÎ½ boxes (Ï€Î¹Î¸Î±Î½Î¬ false positives)
                    width = x2 - x1
                    height = y2 - y1

                    if width > 20 and height > 40:  # Minimum Î±Î½Î¸ÏÏŽÏ€Î¹Î½Î¿ Î¼Î­Î³ÎµÎ¸Î¿Ï‚
                        detections.append([x1, y1, x2, y2, conf])

        return np.array(detections) if detections else np.empty((0, 5))

    def extract_appearance_features(self, frame, box):
        """
        Î•Î¾Î±Î³Ï‰Î³Î® appearance features Î±Ï€ÏŒ bounding box
        Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ color histogram & spatial features

        Args:
            frame: Input frame
            box: Bounding box [x1, y1, x2, y2, conf]

        Returns:
            feature_vector: numpy array
        """
        x1, y1, x2, y2 = map(int, box[:4])

        # Crop Ï„Î¿ Î¬Ï„Î¿Î¼Î¿
        person_crop = frame[y1:y2, x1:x2]

        if person_crop.size == 0:
            return np.zeros(128)  # Empty feature

        # Resize Î³Î¹Î± consistency
        try:
            person_crop = cv2.resize(person_crop, (64, 128))
        except (cv2.error, ValueError, AttributeError):
            return np.zeros(128)

        # Color histogram features (HSV)
        hsv = cv2.cvtColor(person_crop, cv2.COLOR_BGR2HSV)

        # Î§Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÏƒÎµ Ï€Î¬Î½Ï‰/ÎºÎ¬Ï„Ï‰ Î¼Î­ÏÎ¿Ï‚ (torso/legs)
        h = person_crop.shape[0]
        top_half = hsv[:h//2, :]
        bottom_half = hsv[h//2:, :]

        # Histograms
        hist_top_h = cv2.calcHist([top_half], [0], None, [16], [0, 180])
        hist_top_s = cv2.calcHist([top_half], [1], None, [8], [0, 256])
        hist_bottom_h = cv2.calcHist([bottom_half], [0], None, [16], [0, 180])
        hist_bottom_s = cv2.calcHist([bottom_half], [1], None, [8], [0, 256])

        # Normalize
        hist_top_h = cv2.normalize(hist_top_h, hist_top_h).flatten()
        hist_top_s = cv2.normalize(hist_top_s, hist_top_s).flatten()
        hist_bottom_h = cv2.normalize(hist_bottom_h, hist_bottom_h).flatten()
        hist_bottom_s = cv2.normalize(hist_bottom_s, hist_bottom_s).flatten()

        # Aspect ratio feature
        aspect_ratio = (x2 - x1) / (y2 - y1) if (y2 - y1) > 0 else 0

        # Concatenate ÏŒÎ»Î± Ï„Î± features
        features = np.concatenate([
            hist_top_h,      # 16
            hist_top_s,      # 8
            hist_bottom_h,   # 16
            hist_bottom_s,   # 8
            [aspect_ratio]   # 1
        ])

        # Pad to 128 dimensions
        if len(features) < 128:
            features = np.pad(features, (0, 128 - len(features)))

        return features[:128]

    def detect_batch(self, frames):
        """
        Batch detection Î³Î¹Î± Ï€Î¿Î»Î»Î±Ï€Î»Î¬ frames (Ï€Î¹Î¿ Î³ÏÎ®Î³Î¿ÏÎ¿)

        Args:
            frames: List of frames

        Returns:
            List of detections Î³Î¹Î± ÎºÎ¬Î¸Îµ frame
        """
        results = self.model(
            frames,
            conf=self.confidence,
            iou=self.iou_threshold,
            verbose=False,
            classes=[0],
            device=self.device  # Explicit device specification
        )

        all_detections = []
        for result in results:
            detections = []
            boxes = result.boxes

            for box in boxes:
                if int(box.cls) == self.person_class_id:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    conf = float(box.conf[0])

                    # Î¦Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î± Î¼Î¹ÎºÏÏŽÎ½ boxes
                    width = x2 - x1
                    height = y2 - y1

                    if width > 20 and height > 40:
                        detections.append([x1, y1, x2, y2, conf])

            all_detections.append(
                np.array(detections) if detections else np.empty((0, 5))
            )

        return all_detections