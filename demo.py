"""
GUI Application Î³Î¹Î± Human Detection & Tracking - Improved Version
ÎœÎµ REC button Î³Î¹Î± camera recording
"""

import tkinter as tk
from tkinter import filedialog, messagebox
import cv2
from pathlib import Path
import threading
import time
from datetime import datetime

from src.detection.detect import HumanDetector
from src.tracking.tracker import HumanTracker
from src.utils.helpers import draw_tracks, resize_frame, create_output_path


class HumanDetectionApp:
    """ÎšÏÏÎ¹Î± ÎµÏ†Î±ÏÎ¼Î¿Î³Î® Î¼Îµ GUI"""

    def __init__(self, root):
        self.root = root
        self.root.title("Human Detection & Tracking System")
        self.root.geometry("550x550")
        self.root.resizable(False, False)

        # State
        self.is_running = False
        self.is_recording = False
        self.video_writer = None
        self.detector = None
        self.tracker = None
        self.device_preference = tk.StringVar(value="auto")  # auto, cpu, cuda

        self._setup_ui()

    def _setup_ui(self):
        """Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± UI elements"""
        # Title
        title_label = tk.Label(
            self.root,
            text="ğŸ¥ Human Detection & Tracking",
            font=("Arial", 20, "bold"),
            fg="#2c3e50"
        )
        title_label.pack(pady=30)

        # Subtitle
        subtitle = tk.Label(
            self.root,
            text="Powered by YOLOv12 | Real-time Tracking with Re-ID",
            font=("Arial", 10),
            fg="#7f8c8d"
        )
        subtitle.pack()

        # Device selection frame
        device_frame = tk.Frame(self.root)
        device_frame.pack(pady=20)
        
        device_label = tk.Label(
            device_frame,
            text="Device:",
            font=("Arial", 11, "bold"),
            fg="#2c3e50"
        )
        device_label.pack(side=tk.LEFT, padx=5)
        
        # Device options
        device_options = [("Auto-detect", "auto"), ("CPU", "cpu"), ("GPU (CUDA)", "cuda")]
        
        for text, value in device_options:
            rb = tk.Radiobutton(
                device_frame,
                text=text,
                variable=self.device_preference,
                value=value,
                font=("Arial", 10),
                fg="#34495e",
                activebackground="#ecf0f1",
                command=self._update_device_info
            )
            rb.pack(side=tk.LEFT, padx=5)
        
        # Device info label
        self.device_info_label = tk.Label(
            self.root,
            text="",
            font=("Arial", 9),
            fg="#95a5a6"
        )
        self.device_info_label.pack(pady=5)
        self._update_device_info()

        # Frame Î³Î¹Î± buttons
        button_frame = tk.Frame(self.root)
        button_frame.pack(pady=30)

        # Camera button
        camera_btn = tk.Button(
            button_frame,
            text="ğŸ“¹ Real-time Camera",
            font=("Arial", 14),
            bg="#3498db",
            fg="white",
            width=20,
            height=2,
            command=self._start_camera,
            cursor="hand2"
        )
        camera_btn.pack(pady=10)

        # Upload video button
        upload_btn = tk.Button(
            button_frame,
            text="ğŸ“ Upload Video",
            font=("Arial", 14),
            bg="#2ecc71",
            fg="white",
            width=20,
            height=2,
            command=self._upload_video,
            cursor="hand2"
        )
        upload_btn.pack(pady=10)

        # Open Records button
        records_btn = tk.Button(
            button_frame,
            text="ğŸ“‚ Open Records",
            font=("Arial", 14),
            bg="#9b59b6",
            fg="white",
            width=20,
            height=2,
            command=self._open_outputs_folder,
            cursor="hand2"
        )
        records_btn.pack(pady=10)

        # Status label
        self.status_label = tk.Label(
            self.root,
            text="ÎˆÏ„Î¿Î¹Î¼Î¿",
            font=("Arial", 10),
            fg="#95a5a6"
        )
        self.status_label.pack(side=tk.BOTTOM, pady=20)

        # Info
        info_label = tk.Label(
            self.root,
            text="Camera Mode: Î Î¬Ï„Î± 'R' Î³Î¹Î± REC, 'S' Î³Î¹Î± Stop REC, ESC Î³Î¹Î± Î­Î¾Î¿Î´Î¿",
            font=("Arial", 9),
            fg="#95a5a6"
        )
        info_label.pack(side=tk.BOTTOM, pady=5)
    
    def _update_device_info(self):
        """Î•Î½Î·Î¼Î­ÏÏ‰ÏƒÎ· device info label"""
        try:
            from src.detection.detect import get_available_device
            device = get_available_device(self.device_preference.get())
            
            if device == 'cuda':
                try:
                    import torch
                    if torch.cuda.is_available():
                        gpu_name = torch.cuda.get_device_name(0)
                        self.device_info_label.config(
                            text=f"âœ“ GPU Available: {gpu_name}",
                            fg="#27ae60"
                        )
                    else:
                        self.device_info_label.config(
                            text="âš  GPU requested but not available",
                            fg="#e74c3c"
                        )
                except:
                    self.device_info_label.config(
                        text="âš  GPU requested but PyTorch not available",
                        fg="#e74c3c"
                    )
            elif device == 'mps':
                self.device_info_label.config(
                    text="âœ“ Apple Silicon (MPS) Available",
                    fg="#27ae60"
                )
            else:
                self.device_info_label.config(
                    text="â„¹ Using CPU",
                    fg="#95a5a6"
                )
        except Exception as e:
            self.device_info_label.config(
                text="âš  Could not detect device",
                fg="#e74c3c"
            )

    def _open_outputs_folder(self):
        """Î†Î½Î¿Î¹Î³Î¼Î± Ï„Î¿Ï… Ï†Î±ÎºÎ­Î»Î¿Ï… outputs"""
        import subprocess
        import platform
        import os

        output_dir = Path("outputs")
        
        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï†Î±ÎºÎ­Î»Î¿Ï… Î±Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹
        output_dir.mkdir(exist_ok=True)

        output_path = output_dir.absolute()

        try:
            if platform.system() == "Windows":
                # Windows: Ï‡ÏÎ®ÏƒÎ· explorer
                os.startfile(str(output_path))
            elif platform.system() == "Darwin":  # macOS
                subprocess.Popen(["open", str(output_path)])
            else:  # Linux
                subprocess.Popen(["xdg-open", str(output_path)])
            
            self.status_label.config(text=f"Î†Î½Î¿Î¹Î¾Îµ Ï†Î¬ÎºÎµÎ»Î¿Ï‚: {output_path}")
        except Exception as e:
            messagebox.showerror(
                "Î£Ï†Î¬Î»Î¼Î±",
                f"Î”ÎµÎ½ Î¼Ï€ÏŒÏÎµÏƒÎµ Î½Î± Î±Î½Î¿Î¯Î¾ÎµÎ¹ Î¿ Ï†Î¬ÎºÎµÎ»Î¿Ï‚:\n{str(e)}\n\n"
                f"Path: {output_path}"
            )
            self.status_label.config(text="Î£Ï†Î¬Î»Î¼Î± Î±Î½Î¿Î¯Î³Î¼Î±Ï„Î¿Ï‚ Ï†Î±ÎºÎ­Î»Î¿Ï…")

    def _initialize_models(self):
        """Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· detector ÎºÎ±Î¹ tracker"""
        # Î‘Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î®Î´Î· detector Î¼Îµ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÏŒ device, reset
        device_pref = self.device_preference.get()
        if self.detector is not None:
            # Check if device changed
            current_device = self.detector.device
            new_device = device_pref if device_pref != "auto" else None
            if new_device is None:
                # Auto mode - check what would be selected
                from src.detection.detect import get_available_device
                new_device = get_available_device(None)
            
            if current_device != new_device:
                self.detector = None
        
        if self.detector is None:
            self.status_label.config(text="Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Î¿Ï…...")
            self.root.update()

            # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± models directory Î±Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹
            Path("models").mkdir(exist_ok=True)

            try:
                # Device selection
                device = None if device_pref == "auto" else device_pref
                
                # Î§Î±Î¼Î·Î»ÏŒÏ„ÎµÏÎ¿ confidence Î³Î¹Î± ÎºÎ±Î»ÏÏ„ÎµÏÎ¿ detection
                self.detector = HumanDetector(
                    model_path="models/yolo12n.pt",
                    confidence=0.3,  # ÎœÎµÎ¹Ï‰Î¼Î­Î½Î¿ Î±Ï€ÏŒ 0.5
                    device=device
                )
                self.tracker = HumanTracker(
                    max_time_lost=90,  # 3 seconds @ 30fps
                    reid_threshold=0.75,  # Î Î¹Î¿ strict Î³Î¹Î± Î±ÎºÏÎ¹Î²Î­ÏƒÏ„ÎµÏÎ¿ re-ID
                    iou_threshold=0.3
                )
                device_status = f"ÎœÎ¿Î½Ï„Î­Î»Î¿ Ï†Î¿ÏÏ„ÏÎ¸Î·ÎºÎµ! ({self.detector.device_name})"
                self.status_label.config(text=device_status)
            except Exception as e:
                messagebox.showerror(
                    "Î£Ï†Î¬Î»Î¼Î±",
                    f"Î£Ï†Î¬Î»Î¼Î± Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ Î¼Î¿Î½Ï„Î­Î»Î¿Ï…:\n{str(e)}\n\n"
                    "Î¤Î¿ YOLOv12 Î¸Î± ÎºÎ±Ï„Î­Î²ÎµÎ¹ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î± ÏƒÏ„Î·Î½ Ï€ÏÏÏ„Î· ÎµÎºÏ„Î­Î»ÎµÏƒÎ·."
                )
                self.status_label.config(text="Î£Ï†Î¬Î»Î¼Î± Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚")
                return False

        return True

    def _start_camera(self):
        """ÎˆÎ½Î±ÏÎ¾Î· real-time camera detection"""
        if not self._initialize_models():
            return

        self.is_running = True
        self.is_recording = False

        # ÎšÎ»ÎµÎ¯ÏƒÎ¹Î¼Î¿ Ï„Î¿Ï… main window
        self.root.withdraw()

        # Î•ÎºÏ„Î­Î»ÎµÏƒÎ· ÏƒÎµ Î½Î­Î¿ thread
        thread = threading.Thread(target=self._process_camera, daemon=True)
        thread.start()

    def _upload_video(self):
        """Upload ÎºÎ±Î¹ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± video"""
        if not self._initialize_models():
            return

        # Î”Î¹Î¬Î»Î¿Î³Î¿Ï‚ ÎµÏ€Î¹Î»Î¿Î³Î®Ï‚ Î±ÏÏ‡ÎµÎ¯Î¿Ï…
        file_path = filedialog.askopenfilename(
            title="Î•Ï€Î¹Î»Î¿Î³Î® Video",
            filetypes=[
                ("Video files", "*.mp4 *.avi *.mov *.mkv"),
                ("All files", "*.*")
            ],
            initialdir="data"
        )

        if not file_path:
            return

        self.is_running = True

        # ÎšÎ»ÎµÎ¯ÏƒÎ¹Î¼Î¿ Ï„Î¿Ï… main window
        self.root.withdraw()

        # Î•ÎºÏ„Î­Î»ÎµÏƒÎ· ÏƒÎµ Î½Î­Î¿ thread
        thread = threading.Thread(
            target=self._process_video,
            args=(file_path,),
            daemon=True
        )
        thread.start()

    def _start_recording(self, frame_shape, fps):
        """ÎˆÎ½Î±ÏÎ¾Î· recording"""
        if self.is_recording:
            return

        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± output path
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = Path("outputs")
        output_dir.mkdir(exist_ok=True)

        output_path = output_dir / f"camera_recording_{timestamp}.mp4"

        # Video writer
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        height, width = frame_shape[:2]

        self.video_writer = cv2.VideoWriter(
            str(output_path),
            fourcc,
            fps,
            (width, height)
        )

        self.is_recording = True
        self.recording_path = str(output_path)

        print(f"\nğŸ”´ RECORDING STARTED: {output_path}")

    def _stop_recording(self):
        """Î”Î¹Î±ÎºÎ¿Ï€Î® recording"""
        if not self.is_recording:
            return

        self.is_recording = False

        if self.video_writer is not None:
            self.video_writer.release()
            self.video_writer = None

        print(f"\nâ¹ï¸  RECORDING STOPPED")

        # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· dialog Î¼Îµ Ï„Î¿ path
        def show_save_dialog():
            result = messagebox.askyesno(
                "Recording Î‘Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ",
                f"Î¤Î¿ video Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ ÏƒÏ„Î¿:\n{self.recording_path}\n\n"
                "Î˜Î­Î»ÎµÎ¹Ï‚ Î½Î± Î±Î½Î¿Î¯Î¾ÎµÎ¹Ï‚ Ï„Î¿Î½ Ï†Î¬ÎºÎµÎ»Î¿ outputs;"
            )

            if result:
                import subprocess
                import platform

                output_dir = Path("outputs").absolute()

                if platform.system() == "Windows":
                    subprocess.Popen(f'explorer "{output_dir}"')
                elif platform.system() == "Darwin":  # macOS
                    subprocess.Popen(["open", str(output_dir)])
                else:  # Linux
                    subprocess.Popen(["xdg-open", str(output_dir)])

        # Run dialog in main thread
        self.root.after(0, show_save_dialog)

    def _process_camera(self):
        """Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± real-time camera feed Î¼Îµ REC capability"""
        cap = cv2.VideoCapture(0)

        if not cap.isOpened():
            messagebox.showerror(
                "Î£Ï†Î¬Î»Î¼Î±",
                "Î”ÎµÎ½ Î¼Ï€ÏŒÏÎµÏƒÎµ Î½Î± Î±Î½Î¿Î¯Î¾ÎµÎ¹ Î· ÎºÎ¬Î¼ÎµÏÎ±!"
            )
            self.root.deiconify()
            return

        # Camera properties
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        if fps == 0:
            fps = 30  # Default

        # Reset tracker
        self.tracker.reset()

        frame_count = 0
        start_time = time.time()

        cv2.namedWindow("Human Detection - Camera", cv2.WINDOW_NORMAL)

        print("\nğŸ¥ ÎˆÎ½Î±ÏÎ¾Î· real-time detection...")
        print("Controls:")
        print("  R - Start/Resume Recording")
        print("  S - Stop Recording")
        print("  ESC - Exit\n")

        while self.is_running:
            ret, frame = cap.read()

            if not ret:
                break

            frame_count += 1

            # Detection Î¼Îµ improved parameters
            detections = self.detector.detect(frame)

            # Tracking Î¼Îµ appearance features
            tracks = self.tracker.update(detections, frame, frame_count, self.detector)
            stats = self.tracker.get_stats()

            # Visualization
            output_frame = draw_tracks(frame, tracks, stats)

            # FPS calculation
            elapsed = time.time() - start_time
            current_fps = frame_count / elapsed if elapsed > 0 else 0

            # FPS indicator
            cv2.putText(
                output_frame,
                f"FPS: {current_fps:.1f}",
                (output_frame.shape[1] - 150, 35),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.7,
                (0, 255, 0),
                2
            )
            
            # Device indicator
            device_text = self.detector.device_name if self.detector else "N/A"
            cv2.putText(
                output_frame,
                f"Device: {device_text}",
                (output_frame.shape[1] - 200, 65),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (255, 255, 255),
                1
            )

            # REC indicator
            if self.is_recording:
                # Flashing REC indicator
                if frame_count % 20 < 10:
                    cv2.circle(output_frame, (30, 30), 15, (0, 0, 255), -1)
                cv2.putText(
                    output_frame,
                    "REC",
                    (55, 40),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.8,
                    (0, 0, 255),
                    2
                )

                # Write frame
                if self.video_writer is not None:
                    self.video_writer.write(output_frame)

            # Display
            display_frame = resize_frame(output_frame, max_width=1280)
            cv2.imshow("Human Detection - Camera", display_frame)

            # Key handling
            key = cv2.waitKey(1) & 0xFF

            if key == 27:  # ESC - Exit
                if self.is_recording:
                    self._stop_recording()
                break
            elif key == ord('r') or key == ord('R'):  # R - Start recording
                if not self.is_recording:
                    self._start_recording(output_frame.shape, fps)
            elif key == ord('s') or key == ord('S'):  # S - Stop recording
                if self.is_recording:
                    self._stop_recording()

        # Cleanup
        if self.is_recording:
            self._stop_recording()

        cap.release()
        cv2.destroyAllWindows()

        # Î•Ï€Î¹ÏƒÏ„ÏÎ¿Ï†Î® ÏƒÏ„Î¿ main window
        self.root.deiconify()
        self.status_label.config(text="ÎˆÏ„Î¿Î¹Î¼Î¿")

        # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Ï„ÎµÎ»Î¹ÎºÏÎ½ ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÏÎ½
        messagebox.showinfo(
            "Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ Session",
            f"ğŸ“Š Session ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ\n\n"
            f"Frames: {frame_count}\n"
            f"Î£Ï…Î½Î¿Î»Î¹ÎºÎ¿Î¯ Î¬Î½Î¸ÏÏ‰Ï€Î¿Î¹: {stats['total_people']}\n"
            f"ÎœÎ­ÏƒÎ¿ FPS: {current_fps:.1f}\n"
            f"Î”Î¹Î¬ÏÎºÎµÎ¹Î±: {elapsed:.1f}s"
        )

    def _process_video(self, video_path):
        """Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± uploaded video"""
        cap = cv2.VideoCapture(video_path)

        if not cap.isOpened():
            messagebox.showerror(
                "Î£Ï†Î¬Î»Î¼Î±",
                f"Î”ÎµÎ½ Î¼Ï€ÏŒÏÎµÏƒÎµ Î½Î± Î±Î½Î¿Î¯Î¾ÎµÎ¹ Ï„Î¿ video:\n{video_path}"
            )
            self.root.deiconify()
            return

        # Video properties
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        # Output video path
        output_path = create_output_path(video_path)

        # Video writer (Î¼Îµ panel height)
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height + 100))

        # Reset tracker
        self.tracker.reset()

        frame_count = 0
        start_time = time.time()

        cv2.namedWindow("Human Detection - Video", cv2.WINDOW_NORMAL)

        print(f"\nğŸ¬ Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± video: {Path(video_path).name}")
        print(f"Frames: {total_frames} | FPS: {fps}")
        print("Î Î¬Ï„Î± ESC Î³Î¹Î± Î±ÎºÏÏÏ‰ÏƒÎ·\n")

        while self.is_running:
            ret, frame = cap.read()

            if not ret:
                break

            frame_count += 1

            # Detection Î¼Îµ improved parameters
            detections = self.detector.detect(frame)

            # Tracking Î¼Îµ appearance features
            tracks = self.tracker.update(detections, frame, frame_count, self.detector)
            stats = self.tracker.get_stats()

            # Visualization
            output_frame = draw_tracks(frame, tracks, stats)

            # Progress
            progress = (frame_count / total_frames) * 100
            cv2.putText(
                output_frame,
                f"Progress: {progress:.1f}%",
                (output_frame.shape[1] - 220, 35),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.7,
                (255, 255, 0),
                2
            )

            # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· frame
            out.write(output_frame)

            # Display (ÎºÎ¬Î¸Îµ 2 frames Î³Î¹Î± Ï„Î±Ï‡ÏÏ„Î·Ï„Î±)
            if frame_count % 2 == 0:
                display_frame = resize_frame(output_frame, max_width=1280)
                cv2.imshow("Human Detection - Video", display_frame)

            # ESC Î³Î¹Î± Î±ÎºÏÏÏ‰ÏƒÎ·
            key = cv2.waitKey(1) & 0xFF
            if key == 27:  # ESC
                print("\nâŒ Î‘ÎºÏ…ÏÏÎ¸Î·ÎºÎµ Î±Ï€ÏŒ Ï„Î¿Î½ Ï‡ÏÎ®ÏƒÏ„Î·")
                break

            # Print progress
            if frame_count % 30 == 0:
                elapsed = time.time() - start_time
                fps_processing = frame_count / elapsed if elapsed > 0 else 0
                print(f"Frame {frame_count}/{total_frames} | "
                      f"{progress:.1f}% | FPS: {fps_processing:.1f} | "
                      f"People: {stats['current_people']}/{stats['total_people']}")

        cap.release()
        out.release()
        cv2.destroyAllWindows()

        # Î•Ï€Î¹ÏƒÏ„ÏÎ¿Ï†Î® ÏƒÏ„Î¿ main window
        self.root.deiconify()
        self.status_label.config(text="ÎˆÏ„Î¿Î¹Î¼Î¿")

        # Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬
        elapsed = time.time() - start_time
        stats = self.tracker.get_stats()

        if frame_count == total_frames:
            messagebox.showinfo(
                "ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ!",
                f"âœ… Î¤Î¿ video Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ:\n{output_path}\n\n"
                f"ğŸ“Š Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬:\n"
                f"Frames: {frame_count}\n"
                f"Î£Ï…Î½Î¿Î»Î¹ÎºÎ¿Î¯ Î¬Î½Î¸ÏÏ‰Ï€Î¿Î¹: {stats['total_people']}\n"
                f"Î§ÏÏŒÎ½Î¿Ï‚: {elapsed:.1f}s\n"
                f"ÎœÎ­ÏƒÎ¿ FPS: {frame_count/elapsed:.1f}"
            )
            print(f"\nâœ… ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ!")
            print(f"Output: {output_path}")
            print(f"Î£Ï…Î½Î¿Î»Î¹ÎºÎ¿Î¯ Î¬Î½Î¸ÏÏ‰Ï€Î¿Î¹: {stats['total_people']}")
        else:
            print(f"\nâš ï¸ Î”Î¹Î±ÎºÏŒÏ€Î·ÎºÎµ ÏƒÏ„Î¿ frame {frame_count}/{total_frames}")


def main():
    """Entry point"""
    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î±Ï€Î±ÏÎ±Î¯Ï„Î·Ï„Ï‰Î½ directories
    for directory in ["models", "data", "outputs"]:
        Path(directory).mkdir(exist_ok=True)

    print("=" * 60)
    print("ğŸ¥ Human Detection & Tracking System")
    print("=" * 60)
    print("\nğŸ“‹ Features:")
    print("  âœ… YOLOv12 Detection (improved confidence)")
    print("  âœ… Appearance-based Re-identification")
    print("  âœ… Real-time Camera with Recording")
    print("  âœ… Video Upload Processing")
    print("\nğŸ® Camera Controls:")
    print("  R - Start Recording")
    print("  S - Stop Recording")
    print("  ESC - Exit")
    print("\n" + "=" * 60 + "\n")

    # Î•ÎºÏ„Î­Î»ÎµÏƒÎ· GUI
    root = tk.Tk()
    app = HumanDetectionApp(root)
    root.mainloop()


if __name__ == "__main__":
    main()